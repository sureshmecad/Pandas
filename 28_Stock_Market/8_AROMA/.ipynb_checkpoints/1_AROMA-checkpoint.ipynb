{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/stock-market-analysis-using-arima-8731ded2447a\n",
    "\n",
    "https://github.com/pierpaolo28/Kaggle-Challenges/blob/master/stock-market-analysis-and-time-series-prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA (AutoRegressive Integrated Moving Average)\n",
    "\n",
    "The acronym of ARIMA stands for [1]:\n",
    "- **AutoRegressive** = the model takes advantage of the connection between a predefined number of lagged observations and the current one.\n",
    "\n",
    "- **Integrated** = differencing between raw observations (eg. subtracting observations at different time steps).\n",
    "\n",
    "- **Moving Average** = the model takes advantage of the relationship between the residual error and the observations.\n",
    "\n",
    "The ARIMA model makes use of three main parameters (p,d,q). These are:\n",
    "\n",
    "**p** = number of lag observations.\n",
    "\n",
    "**d** = the degree of differencing.\n",
    "\n",
    "**q** = the size of the moving average window.\n",
    "\n",
    "ARIMA can lead to particularly good results if applied to short time predictions (like has been used in this example). Different code models of ARIMA in Python are available here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepusuresh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\deepusuresh\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, I loaded the specific Microsoft (MSFT) dataset among all the other available. This dataset is composed of seven different features (Figure 1)\n",
    "\n",
    "\n",
    "- In this post, I will just examine the “Open” stock prices feature. This same analysis can be repeated for most of the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/Data/Stocks/msft.us.txt\").fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "lag_plot(df['Open'], lag=5)\n",
    "plt.title('Microsoft Autocorrelation plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df[0:int(len(df)*0.8)], df[int(len(df)*0.8):]\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Microsoft Prices')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.plot(df['Open'], 'blue', label='Training Data')\n",
    "plt.plot(test_data['Open'], 'green', label='Testing Data')\n",
    "plt.xticks(np.arange(0,7982, 1300), df['Date'][0:7982:1300])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to evaluate the ARIMA model, I decided to use two different error functions: Mean Squared Error (MSE) and Symmetric Mean Absolute Percentage Error (SMAPE). SMAPE is commonly used as an accuracy measure based on relative errors.\n",
    "\n",
    "\n",
    "- SMAPE is not currently supported in Scikit-learn as a loss function I, therefore, had first to create this function on my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_kun(y_true, y_pred):\n",
    "    return np.mean((np.abs(y_pred - y_true) * 200/ (np.abs(y_pred) + np.abs(y_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Afterwards, I created the ARIMA model to be used for this implementation. I decided to set in this case p=5, d=1 and q=0 as the ARIMA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ar = train_data['Open'].values\n",
    "test_ar = test_data['Open'].valueshistory = [x for x in train_ar]\n",
    "print(type(history))\n",
    "predictions = list()\n",
    "for t in range(len(test_ar)):\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test_ar[t]\n",
    "    history.append(obs)\n",
    "error = mean_squared_error(test_ar, predictions)\n",
    "print('Testing Mean Squared Error: %.3f' % error)\n",
    "error2 = smape_kun(test_ar, predictions)\n",
    "print('Symmetric mean absolute percentage error: %.3f' % error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The loss results for this model are available below. According to the MSE, the model loss is quite low but for SMAPE is instead consistently higher. One of the main reason for this discrepancy is because SMAPE is commonly used loss a loss function for Time Series problems and can, therefore, provide a more reliable analysis. That showed there is still room for improvement of our model.\n",
    "\n",
    "\n",
    "- Finally, I decided to plot the training, test and predicted prices against time to visualize how did the model performed against the actual prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(df['Open'], 'green', color='blue', label='Training Data')\n",
    "plt.plot(test_data.index, predictions, color='green', marker='o', linestyle='dashed', \n",
    "         label='Predicted Price')\n",
    "plt.plot(test_data.index, test_data['Open'], color='red', label='Actual Price')\n",
    "plt.title('Microsoft Prices Prediction')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.xticks(np.arange(0,7982, 1300), df['Date'][0:7982:1300])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(test_data.index, predictions, color='green', marker='o', linestyle='dashed',label='Predicted Price')\n",
    "plt.plot(test_data.index, test_data['Open'], color='red', label='Actual Price')\n",
    "plt.legend()\n",
    "plt.title('Microsoft Prices Prediction')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Prices')\n",
    "plt.xticks(np.arange(6386,7982, 300), df['Date'][6386:7982:300])\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
